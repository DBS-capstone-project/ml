{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11205113,"sourceType":"datasetVersion","datasetId":6996221}],"dockerImageVersionId":30918,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T10:51:38.185076Z","iopub.execute_input":"2025-04-05T10:51:38.185292Z","iopub.status.idle":"2025-04-05T10:51:39.068713Z","shell.execute_reply.started":"2025-04-05T10:51:38.185271Z","shell.execute_reply":"2025-04-05T10:51:39.067964Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/frankendata/final_fix_V2_merged_emotion_dataset.csv\")\ndata.head","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T10:51:39.069601Z","iopub.execute_input":"2025-04-05T10:51:39.070075Z","iopub.status.idle":"2025-04-05T10:51:39.219217Z","shell.execute_reply.started":"2025-04-05T10:51:39.070045Z","shell.execute_reply":"2025-04-05T10:51:39.21784Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X, y = data['text'], data['label']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T10:51:39.220892Z","iopub.execute_input":"2025-04-05T10:51:39.221157Z","iopub.status.idle":"2025-04-05T10:51:39.229415Z","shell.execute_reply.started":"2025-04-05T10:51:39.221133Z","shell.execute_reply":"2025-04-05T10:51:39.228486Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\ndata = pd.read_csv(\"/kaggle/input/frankendata/final_fix_V2_merged_emotion_dataset.csv\")\nprint(data.head())\n\nX, y = data['text'], data['label']\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional, LeakyReLU\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nimport pickle\n\nencoder = LabelEncoder()\ny_encoded = encoder.fit_transform(y)\n\ntokenizer = Tokenizer(num_words=30000, oov_token=\"<OOV>\")\ntokenizer.fit_on_texts(X)\nX_sequences = tokenizer.texts_to_sequences(X)\nX_padded = pad_sequences(X_sequences, maxlen=100, padding='post')\n\nwith open(\"tokenizer.pkl\", \"wb\") as f:\n    pickle.dump(tokenizer, f)\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X_padded, y_encoded, test_size=0.2, random_state=42\n)\n\nfrom sklearn.utils import class_weight\nclass_weights_values = class_weight.compute_class_weight(\n    class_weight='balanced',\n    classes=np.unique(y_train),\n    y=y_train\n)\nclass_weights = dict(enumerate(class_weights_values))\n\n\nearly_stopper = tf.keras.callbacks.EarlyStopping(\n    monitor='val_loss', patience=3, restore_best_weights=True\n)\n\n\nmodel = Sequential([\n    Embedding(input_dim=30000, output_dim=256, input_length=100),\n    Bidirectional(LSTM(32, recurrent_dropout=0.2)),\n    Dense(16, kernel_regularizer=tf.keras.regularizers.l2(0.006)),\n    Dropout(0.3),\n    LeakyReLU(),\n    Dense(6, activation='softmax')\n])\n\nmodel.compile(\n    loss='sparse_categorical_crossentropy',\n    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n    metrics=['accuracy']\n)\n\nmodel.summary()\n\nhistory = model.fit(\n    X_train, \n    y_train, \n    epochs=20, \n    batch_size=32, \n    validation_split=0.2, \n    class_weight=class_weights,\n    callbacks=[early_stopper]\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T10:51:39.231318Z","iopub.execute_input":"2025-04-05T10:51:39.231546Z","iopub.status.idle":"2025-04-05T10:55:46.956225Z","shell.execute_reply.started":"2025-04-05T10:51:39.231524Z","shell.execute_reply":"2025-04-05T10:55:46.955498Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(dict(zip(encoder.classes_, encoder.transform(encoder.classes_))))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T11:03:07.730632Z","iopub.execute_input":"2025-04-05T11:03:07.73099Z","iopub.status.idle":"2025-04-05T11:03:07.736006Z","shell.execute_reply.started":"2025-04-05T11:03:07.730923Z","shell.execute_reply":"2025-04-05T11:03:07.735103Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pickle\n\nwith open(\"tokenizer.pkl\", \"wb\") as f:\n    pickle.dump(tokenizer, f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T10:56:28.91407Z","iopub.execute_input":"2025-04-05T10:56:28.914395Z","iopub.status.idle":"2025-04-05T10:56:28.9387Z","shell.execute_reply.started":"2025-04-05T10:56:28.914356Z","shell.execute_reply":"2025-04-05T10:56:28.93805Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.save(\"emotion_classifier_model_rev2.h5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T10:56:30.720427Z","iopub.execute_input":"2025-04-05T10:56:30.720715Z","iopub.status.idle":"2025-04-05T10:56:30.873189Z","shell.execute_reply.started":"2025-04-05T10:56:30.720693Z","shell.execute_reply":"2025-04-05T10:56:30.872463Z"}},"outputs":[],"execution_count":null}]}